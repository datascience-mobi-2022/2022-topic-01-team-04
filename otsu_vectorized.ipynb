{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# otsu thresholding\n",
    "\n",
    "\n",
    "from cmath import nan\n",
    "\n",
    "\n",
    "def otsu_vectorized(img,x):\n",
    "    import matplotlib.pyplot\n",
    "    import numpy\n",
    "\n",
    "   # load histogram, Mathematische werte aus Histogramm rausgreifen\n",
    "    n, bins = numpy.histogram(img.flatten(),bins = x)\n",
    "  \n",
    "   # initialize threshold value (T = 0) \n",
    "    thres = 0\n",
    "    copy = img.copy()\n",
    "\n",
    "    # create list to store values of within class variance for each threshold value\n",
    "    wcv = list()\n",
    "    \n",
    "    # set up initial values\n",
    "    for i in range(0,len(n)):\n",
    "        wclv = 0\n",
    "        w0_sum = 0\n",
    "        mean_sum0 = 0\n",
    "        v0_sum = 0\n",
    "        mean_sum1 = 0\n",
    "        v1_sum = 0\n",
    "        w0 = 0\n",
    "        w1 = 0\n",
    "        w1_sum = 0\n",
    "\n",
    "        #sum up the probabilites of each intensity value;  and the mean value (sind noch nicht happy mit der definition :()\n",
    "        w0_sum = numpy.sum(numpy.array(n[0:i+1]))\n",
    "        mean_sum0 = numpy.sum((numpy.array(bins[0:i+1])*numpy.array(n[0:i+1])))\n",
    "            \n",
    "        # background class probabilites and class mean levels\n",
    "        w0 = w0_sum / sum(n)  \n",
    "        if(sum(n[0:i+1]) != 0):  \n",
    "             mean_0 = mean_sum0 / sum(n[0:i+1])\n",
    "        else: mean_0 = 0\n",
    "        \n",
    "        # compute background class variance\n",
    "\n",
    "        v0_sum = numpy.sum((numpy.array((bins[0:i+1]-mean_0)** 2)*numpy.array(n[0:i+1])))\n",
    "        v0 = v0_sum / sum(n[0:i+1])\n",
    "        \n",
    "        # sum up the probabilites of each intensity value;  and the mean value\n",
    "        w1_sum = numpy.sum(numpy.array(n[i+1:len(n)]))\n",
    "        mean_sum1 = numpy.sum((numpy.array(bins[i+1:len(n)])*numpy.array(n[i+1:len(n)])))\n",
    "            \n",
    "        # compute foreground class probabilities and class mean levels    \n",
    "        w1 = w1_sum / sum(n)\n",
    "        if(sum(n[i+1:len(n)]) != 0):\n",
    "            mean_1 = mean_sum1 / sum(n[i+1:len(n)])\n",
    "        else: mean_1 = 0\n",
    "\n",
    "        # compute foreground class variance \n",
    "        v1_sum = numpy.sum((numpy.array((bins[i+1:len(n)]-mean_1)** 2)*numpy.array(n[i+1:len(n)])))\n",
    "       \n",
    "        if( sum(n[i+1:len(n)]) != 0):\n",
    "            v1 = v1_sum / sum(n[i+1:len(n)])\n",
    "        else: v1 = 0\n",
    "\n",
    "        # compute within class variance and append to list\n",
    "        wclv = (w0 * v0) + (w1 * v1)\n",
    "        wcv.append(wclv)\n",
    "\n",
    "    # select optimal threshold value, minimum value of within class variance\n",
    "    optimal_thres = min(wcv)\n",
    "\n",
    "    #select optimal threshold in the list\n",
    "    l = 0\n",
    "    while l < len(wcv):\n",
    "        if wcv[l] == optimal_thres: thres = bins[l]\n",
    "        l += 1\n",
    "   # index = numpy.where(numpy.array(wcv) == optimal_thres)\n",
    "    #thres = bins[index]\n",
    "    #perform image clipping \n",
    "    copy[copy < thres] = 0\n",
    "    copy[copy >= thres] = 1\n",
    "\n",
    "    return copy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: QtAgg\n",
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy.ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os, os.path\n",
    "\n",
    "imgs = []\n",
    "path = r\"data\\Otsu_data\\NIH3T3\\img\"\n",
    "for f in os.listdir(path):\n",
    "    imgs.append(imread(os.path.join(path,f)))\n",
    "\n",
    "imgs_gt = []\n",
    "path = r\"data\\Otsu_data\\NIH3T3\\gt\"\n",
    "for f in os.listdir(path):\n",
    "    imgs_gt.append(imread(os.path.join(path,f)))\n",
    "\n",
    "imgs_1 = []\n",
    "path = r\"data\\Otsu_data\\N2DH-GOWT1\\img\"\n",
    "for f in os.listdir(path):\n",
    "    imgs_1.append(imread(os.path.join(path,f)))\n",
    "\n",
    "imgs_gt_1 = []\n",
    "path = r\"data\\Otsu_data\\N2DH-GOWT1\\gt\"\n",
    "for f in os.listdir(path):\n",
    "    imgs_gt_1.append(imread(os.path.join(path,f)))\n",
    "\n",
    "imgs_2 = []\n",
    "path = r\"data\\Otsu_data\\N2DL-HeLa\\img\"\n",
    "for f in os.listdir(path):\n",
    "    imgs_2.append(imread(os.path.join(path,f)))\n",
    "\n",
    "imgs_gt_2 = []\n",
    "path = r\"data\\Otsu_data\\N2DL-HeLa\\gt\"\n",
    "for f in os.listdir(path):\n",
    "    imgs_gt_2.append(imread(os.path.join(path,f)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_1 = otsu_vectorized(imgs[0], 256)\n",
    "\n",
    "#figure()\n",
    "#imshow(img_1,'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def f_dice(x): # POSITIVE PIXELS = FOREGROUND\n",
    "    gt = ground_truth[x] \n",
    "    pt = tresholded[x] \n",
    "    tp=0\n",
    "    tn=0\n",
    "    fp=0\n",
    "    fn=0\n",
    "    h = gt.shape[0]\n",
    "    w = gt.shape[1]\n",
    "    for x, y in np.ndindex((h,w)):\n",
    "        if gt[x,y]!=0:\n",
    "            if pt[x,y]!=0:\n",
    "                tp+=1\n",
    "            else:\n",
    "                fn+=1\n",
    "        else:\n",
    "            if pt[x,y]!=0:\n",
    "                fp+=1\n",
    "            else:\n",
    "                tn+=1 \n",
    "    f_dsc= 2*tp/(2*tp+fn+fp)\n",
    "    return f_dsc\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8943783223933183]\n"
     ]
    }
   ],
   "source": [
    "tresholded = [img_1, imgs[2]]\n",
    "ground_truth = imgs_gt\n",
    "dsc_2 = []\n",
    "dsc_2.append(f_dice(0))\n",
    "print(dsc_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('dataanalysis0104_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "73a5aaef6c11b1ea6e162ad69f2e79f73d9b6fd099813d04ec92d64c4323e461"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
